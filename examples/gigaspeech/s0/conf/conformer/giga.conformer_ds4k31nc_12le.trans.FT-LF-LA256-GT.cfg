train_config=conf/conformer/giga.conformer_ds4k31nc_12le.trans.FT-LF-LA256-GT.yaml
exp_name=giga.conformer_ds4k31nc_12le.trans.FT-LF-LA256-GT

wandb_proj=$exp_name
WANDB_PROJECT=$wandb_proj

data_type="shard"

base_dir=/data/exps/
data_dir=$base_dir/data

training_shards_list=/data/bootes_data/local_speech-shards/train/en/gigaspeech_xl/shards.gigaspeech_xl.list
dev_shards_list=/shared/speech-shards/dev/en/GigaSpeech/gs_dev_shards.list

init_checkpoint="/shared/experiments/paper_replacing_MHA/models/giga.conformer_MHA12L-longform_avg5_at_44.pt"

decode_modes="attention_rescoring ctc_greedy_search"
average_num=10

# number of jobs to execute for data prep portion
nj=16

extra_train_args="--print_model"
